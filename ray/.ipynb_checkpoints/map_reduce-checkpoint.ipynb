{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca49ba94-dc84-4697-bcb3-181420609fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaxiZones.csv exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"TaxiZones.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"{file_path} exists.\")\n",
    "else:\n",
    "    print(f\"{file_path} does not exist. Performing extra action...\")\n",
    "    \n",
    "    !curl -o data.csv https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
    "    !tail -n +2 data.csv > data_quoted.csv\n",
    "    !sed 's/\"//g' data_quoted.csv > TaxiZones.csv\n",
    "    !rm data.csv data_quoted.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1efdb-96ab-4162-93a6-a57e4545b3aa",
   "metadata": {},
   "source": [
    "## On Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f279b06-7ed3-47bb-9df4-ba22c4a1d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/02 10:02:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "            SparkSession\n",
    "                .builder\n",
    "                .appName(\"MapReduceApp\")\n",
    "                .master(\"local[4]\")\n",
    "                .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43fd745-4585-4142-917b-25e671c0509e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1,EWR,Newark Airport,EWR',\n",
       " '2,Queens,Jamaica Bay,Boro Zone',\n",
       " '3,Bronx,Allerton/Pelham Gardens,Boro Zone',\n",
       " '4,Manhattan,Alphabet City,Yellow Zone',\n",
       " '5,Staten Island,Arden Heights,Boro Zone',\n",
       " '6,Staten Island,Arrochar/Fort Wadsworth,Boro Zone',\n",
       " '7,Queens,Astoria,Boro Zone',\n",
       " '8,Queens,Astoria Park,Boro Zone',\n",
       " '9,Queens,Auburndale,Boro Zone',\n",
       " '10,Queens,Baisley Park,Boro Zone']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiZonesRdd = sc.textFile(\"TaxiZones.csv\")\n",
    "taxiZonesRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b91f9f-557d-42ce-bd31-eec44c568740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EWR', 1),\n",
       " ('Manhattan', 69),\n",
       " ('Brooklyn', 61),\n",
       " ('Unknown', 1),\n",
       " ('N/A', 1),\n",
       " ('Queens', 69),\n",
       " ('Bronx', 43),\n",
       " ('Staten Island', 20)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce map\n",
    "boroughCountRdd = (\n",
    "                    taxiZonesRdd\n",
    "                        .map( lambda zone: zone.split(\",\") )\n",
    "                        .map( lambda zone: (zone[1], 1))\n",
    "                        .reduceByKey( lambda value1, value2: value1 + value2 )\n",
    "                  )\n",
    "\n",
    "boroughCountRdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f57011-6af1-40dc-bd07-2bc42024ad57",
   "metadata": {},
   "source": [
    "## On Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "761c770a-5fa4-453e-9468-739cb68ad205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 10:02:13,537\tINFO worker.py:1786 -- Started a local Ray instance.\n",
      "2024-10-02 10:02:17,119\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-10-02_10-02-11_210831_80229/logs/ray-data\n",
      "2024-10-02 10:02:17,120\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadText] -> AllToAllOperator[Repartition] -> TaskPoolMapOperator[Map(extract_lines)->Map(select_data)] -> AllToAllOperator[Aggregate]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44482c1cb5e542a096af4b1c29ed7f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9578bca690fe42f896812e0000e8da3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadText->SplitBlocks(24) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ae79f17d08491397b48ded76b86e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Repartition 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5786568ad9d4bc99420cb652153c410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split Repartition 3:   0%|                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cc0a1e8b184f1b935c496a28755292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Map(extract_lines)->Map(select_data) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c50872d094402d8a56b8af57fa4a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd06aa3206f4b8ab8ebf6678f2d0642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 6:   0%|                                                                                          …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba89f94d401541bbaa783d287b84f600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 7:   0%|                                                                                          …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae55569179a7495f9dec61dc560e02b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 8:   0%|                                                                                       …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('Bronx', 43),\n",
       " ('Brooklyn', 61),\n",
       " ('EWR', 1),\n",
       " ('Manhattan', 69),\n",
       " ('N/A', 1),\n",
       " ('Queens', 69),\n",
       " ('Staten Island', 20),\n",
       " ('Unknown', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m *\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m h\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m e\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m e\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m e\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m m\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m g\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m h\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m g\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m -\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m l\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m d\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m m\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80266)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m p\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m p\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m e\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m s\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m p\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m s\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m u\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m e\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m s\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m f\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m r\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m g\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m s\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m p\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m -\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m w\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m d\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m i\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m t\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m w\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m m\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m b\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m o\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m a\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m f\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m u\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m y\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m d\n",
      "\u001b[36m(apply_map pid=80264)\u001b[0m n\n",
      "\u001b[36m(apply_map pid=80260)\u001b[0m z\n",
      "\u001b[36m(apply_map pid=80260)\u001b[0m c\n",
      "\u001b[36m(apply_map pid=80260)\u001b[0m c\n",
      "\u001b[36m(apply_map pid=80260)\u001b[0m c\n",
      "\u001b[36m(apply_map pid=80260)\u001b[0m c\n",
      "\u001b[36m(apply_map pid=80260)\u001b[0m c\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "def extract_lines(row: Dict[str, str]) -> Dict[str,str]:\n",
    "    row['text'] = row['text'].split(',')\n",
    "    return row\n",
    "\n",
    "def select_data(row: Dict[str, str]) -> Dict[str,str]:\n",
    "    row['text'] = row['text'][1]\n",
    "    return row\n",
    "\n",
    "taxi_zones_ds = (\n",
    "    ray.data\n",
    "    .read_text(\"TaxiZones.csv\")\n",
    "    .repartition(num_blocks=3)\n",
    "    .map(extract_lines)\n",
    "    .map(select_data)\n",
    "    .groupby('text')\n",
    "    .count()\n",
    "    .take_all()\n",
    ")\n",
    "\n",
    "result = [(x['text'],x['count()']) for x in taxi_zones_ds]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc4e404-de93-43eb-bc41-67883e7252de",
   "metadata": {},
   "source": [
    "## Working Example\n",
    "\n",
    "**Via Python Data Types**\n",
    "\n",
    "From [here](https://docs.ray.io/en/latest/ray-core/examples/map_reduce.html#a-simple-mapreduce-example-with-ray-core)\n",
    "\n",
    "![](../media/map_reduce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730db100-4f96-42dd-8951-fd3eaba46336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "zen_of_python = subprocess.check_output([\"python\", \"-c\", \"import this\"])\n",
    "corpus = zen_of_python.split()\n",
    "\n",
    "num_partitions = 3\n",
    "chunk = len(corpus) // num_partitions\n",
    "partitions = [\n",
    "    corpus[i * chunk: (i + 1) * chunk] for i in range(num_partitions)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d916a8-e288-4538-b13a-30bd2246d792",
   "metadata": {},
   "source": [
    "The corpus is equivalent to the full list of words here *The Zen of Python*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be345bf-7024-46d2-ba17-a1c715e9223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'The',\n",
       " b'Zen',\n",
       " b'of',\n",
       " b'Python,',\n",
       " b'by',\n",
       " b'Tim',\n",
       " b'Peters',\n",
       " b'Beautiful',\n",
       " b'is',\n",
       " b'better']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8defb6f6-c3ad-4285-b596-a9a4f3d8d41e",
   "metadata": {},
   "source": [
    "The repartitionning makes multiple batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4500109-f2c9-43fe-920e-0a6152ae03f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'The', b'Zen'], [b'Although', b'practicality'], [b'is', b'better']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[:2] for x in partitions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9503d56-1ff3-4011-b8d4-d4cb7249e90d",
   "metadata": {},
   "source": [
    "This is a mapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47830657-cd0a-4042-b1cc-5d740872c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(document):\n",
    "    for word in document.lower().split():\n",
    "        yield word, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cac82c-ed78-4a22-9586-24f3d213759d",
   "metadata": {},
   "source": [
    "And this is the way the reduce is performed:\n",
    "\n",
    "Check\n",
    "1. We apply via `apply_map`\n",
    "2. We reduce via `apply_reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b075ddcf-3aa1-4a5b-9d5e-01d33404a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "@ray.remote\n",
    "def apply_map(corpus, num_partitions=3):\n",
    "    map_results = [list() for _ in range(num_partitions)]\n",
    "    for document in corpus:\n",
    "        for result in map_function(document):\n",
    "            first_letter = result[0].decode(\"utf-8\")[0]\n",
    "            print(first_letter)\n",
    "            word_index = ord(first_letter) % num_partitions\n",
    "            map_results[word_index].append(result)\n",
    "    return map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74769ca9-c3d7-4c59-8beb-45143e45735f",
   "metadata": {},
   "source": [
    "Let first apply the map over several partitions:\n",
    "\n",
    "- Note the strategy for broadcasting to each partition accordingly (shuffling)\n",
    "  - Take the first letter\n",
    "  - Convert it to ordinal so `A`→ 65 via `ord(first_letter)`\n",
    "  - Take the modulo to say 0,1,2\n",
    "  - Write into `map_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b15051b-fc89-482c-a5c7-8c1d94b4221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapper 0, return value 0: [(b'of', 1), (b'is', 1)]\n",
      "Mapper 0, return value 1: [(b'python,', 1), (b'peters', 1)]\n",
      "Mapper 0, return value 2: [(b'the', 1), (b'zen', 1)]\n",
      "Mapper 1, return value 0: [(b'unless', 1), (b'in', 1)]\n",
      "Mapper 1, return value 1: [(b'although', 1), (b'practicality', 1)]\n",
      "Mapper 1, return value 2: [(b'beats', 1), (b'errors', 1)]\n",
      "Mapper 2, return value 0: [(b'is', 1), (b'is', 1)]\n",
      "Mapper 2, return value 1: [(b'although', 1), (b'a', 1)]\n",
      "Mapper 2, return value 2: [(b'better', 1), (b'than', 1)]\n"
     ]
    }
   ],
   "source": [
    "map_results = [\n",
    "    apply_map\n",
    "    .options(num_returns=num_partitions)\n",
    "    .remote(data, num_partitions)\n",
    "    for data in partitions\n",
    "]\n",
    "\n",
    "for i in range(num_partitions):\n",
    "    mapper_results = ray.get(map_results[i])\n",
    "    for j, result in enumerate(mapper_results):\n",
    "        print(f\"Mapper {i}, return value {j}: {result[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701a64c-4512-4940-9f86-6736159aab34",
   "metadata": {},
   "source": [
    "Then let reduce by shuffling the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c4ab81-5441-48cc-8c1b-88e5ac35eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def apply_reduce(*results):\n",
    "    reduce_results = dict()\n",
    "    for res in results:\n",
    "        for key, value in res:\n",
    "            if key not in reduce_results:\n",
    "                reduce_results[key] = 0\n",
    "            reduce_results[key] += value\n",
    "\n",
    "    return reduce_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e63724-9f72-4ba7-9124-15ee66cd3ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is: 10\n",
      "better: 8\n",
      "than: 8\n",
      "the: 6\n",
      "to: 5\n",
      "of: 3\n",
      "although: 3\n",
      "be: 3\n",
      "unless: 2\n",
      "one: 2\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in range(num_partitions):\n",
    "    outputs.append(\n",
    "        apply_reduce.remote(*[partition[i] for partition in map_results])\n",
    "    )\n",
    "\n",
    "counts = {k: v for output in ray.get(outputs) for k, v in output.items()}\n",
    "\n",
    "sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "for count, _ in zip(sorted_counts,range(10)):\n",
    "    print(f\"{count[0].decode('utf-8')}: {count[1]}\")\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ffcef-5470-4010-a135-6115cf7f5340",
   "metadata": {},
   "source": [
    "## Now same usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547ebd97-49fd-4876-8ada-30a200c41803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EWR', 'Queens'], ['Brooklyn', 'Manhattan'], ['Brooklyn', 'Brooklyn']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "corpus = []\n",
    "with open('TaxiZones.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\\\"') \n",
    "    for row in reader:\n",
    "        corpus.append(row[1])\n",
    "        \n",
    "num_partitions = 3\n",
    "chunk = len(corpus) // num_partitions\n",
    "partitions = [\n",
    "    corpus[i * chunk: (i + 1) * chunk] for i in range(num_partitions)\n",
    "]\n",
    "[x[:2] for x in partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f7fb3ac-d69a-41d2-8816-ef30aec423cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapper 0, return value 0: [('island', 1), ('island', 1)]\n",
      "Mapper 0, return value 1: [('manhattan', 1), ('staten', 1)]\n",
      "Mapper 0, return value 2: [('ewr', 1), ('queens', 1)]\n",
      "Mapper 1, return value 0: [('island', 1), ('island', 1)]\n",
      "Mapper 1, return value 1: [('manhattan', 1), ('staten', 1)]\n",
      "Mapper 1, return value 2: [('brooklyn', 1), ('brooklyn', 1)]\n",
      "Mapper 2, return value 0: [('island', 1), ('island', 1)]\n",
      "Mapper 2, return value 1: [('manhattan', 1), ('staten', 1)]\n",
      "Mapper 2, return value 2: [('brooklyn', 1), ('brooklyn', 1)]\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def apply_map(corpus, num_partitions=3):\n",
    "    map_results = [list() for _ in range(num_partitions)]\n",
    "    for document in corpus:\n",
    "        for result in map_function(document):\n",
    "            first_letter = result[0][0]\n",
    "            word_index = ord(first_letter) % num_partitions # Strategy to broadcast to each partition\n",
    "            map_results[word_index].append(result)\n",
    "    return map_results\n",
    "\n",
    "map_results = [\n",
    "    apply_map\n",
    "    .options(num_returns=num_partitions)\n",
    "    .remote(data, num_partitions)\n",
    "    for data in partitions\n",
    "]\n",
    "\n",
    "for i in range(num_partitions):\n",
    "    mapper_results = ray.get(map_results[i])\n",
    "    for j, result in enumerate(mapper_results):\n",
    "        print(f\"Mapper {i}, return value {j}: {result[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e075a1f-6ab8-4d24-b621-40cbe869591c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhattan: 69\n",
      "queens: 69\n",
      "brooklyn: 61\n",
      "bronx: 43\n",
      "island: 20\n",
      "staten: 20\n",
      "unknown: 1\n",
      "ewr: 1\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in range(num_partitions):\n",
    "    outputs.append(\n",
    "        apply_reduce.remote(*[partition[i] for partition in map_results])\n",
    "    )\n",
    "\n",
    "counts = {k: v for output in ray.get(outputs) for k, v in output.items()}\n",
    "\n",
    "sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "for count, _ in zip(sorted_counts,range(10)):\n",
    "    print(f\"{count[0]}: {count[1]}\")\n",
    "print('...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
